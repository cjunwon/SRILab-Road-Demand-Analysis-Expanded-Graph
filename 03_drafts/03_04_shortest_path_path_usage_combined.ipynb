{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import igraph as ig\n",
    "import pickle\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing intermediate_files/Node_to_Node_pairs.pickle...\n",
      "Importing intermediate_files/igraph.pickle...\n",
      "Importing intermediate_files/nodes_edges_ucla_big_graph.pickle...\n",
      "Importing intermediate_files/LODES_adjusted_block_pairing_count_list.pickle...\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing intermediate_files/Node_to_Node_pairs.pickle...\")\n",
    "with open(r'intermediate_files/Node_to_Node_pairs.pickle', 'rb') as handle:\n",
    "    Node_to_Node_pairs = pickle.load(handle)\n",
    "\n",
    "print(\"Importing intermediate_files/igraph.pickle...\")\n",
    "with open(r'intermediate_files/igraph.pickle', 'rb') as handle:\n",
    "    g = pickle.load(handle)\n",
    "\n",
    "print(\"Importing intermediate_files/nodes_edges_ucla_big_graph.pickle...\")\n",
    "with open(r'nodes_edges_ucla_big_graph.pickle', 'rb') as handle:\n",
    "    B_matrix_sliced,B_matrix_str_sliced,nodes_coordinates_array = pickle.load(handle)\n",
    "\n",
    "print(\"Importing intermediate_files/LODES_adjusted_block_pairing_count_list.pickle...\")\n",
    "with open(r'intermediate_files/LODES_adjusted_block_pairing_count_list.pickle', 'rb') as handle:\n",
    "    Block_to_Block_Pairs, LODES_adjusted, block_pairing_count_list = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'nodes_edges_weighted.pickle', 'rb') as handle:\n",
    "    B_matrix_weighted, node_coordinates_weighted = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_LODES = [value for value, count in zip(LODES_adjusted, block_pairing_count_list) for _ in range(count)]\n",
    "expanded_LODES = np.array(expanded_LODES, dtype='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lodes_lookup = {node_pair: lodes_val for node_pair, lodes_val in zip(Node_to_Node_pairs, expanded_LODES)}\n",
    "\n",
    "def get_lodes_from_node_pair(node_pair):\n",
    "    # Directly return the LODES_vals using the node_pair as the key\n",
    "    return lodes_lookup.get(node_pair, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize array of 0s with 10 columns and append to B_matrix_sliced\n",
    "zero_columns = np.zeros((B_matrix_sliced.shape[0], 10))\n",
    "B_matrix_weighted_array = np.hstack((B_matrix_sliced, zero_columns))\n",
    "B_matrix_weighted_array = B_matrix_weighted_array.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting B_matrix_weighted to a dictionary for faster lookups (O(1) lookups, faster)\n",
    "B_matrix_weighted_dict = {(row[0].astype(int), row[1].astype(int)): row for row in B_matrix_weighted_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Node_to_Node_pairs_dict...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Node_to_Node_pairs_dict...\")\n",
    "Node_to_Node_pairs_dict = defaultdict(list)\n",
    "\n",
    "for key, value in Node_to_Node_pairs:\n",
    "    Node_to_Node_pairs_dict[key].append(value)\n",
    "\n",
    "Node_to_Node_pairs_len = len(Node_to_Node_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141593"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Node_to_Node_pairs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6m/88dwrhnx7m3cybxwl1p0rtq40000gn/T/ipykernel_78391/3996153590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNode_to_Node_pairs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "Node_to_Node_pairs_dict[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting origin_nodes_list...\n",
      "Creating Node_to_Node_pairs_dict_subset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Subsetting origin_nodes_list...\")\n",
    "origin_nodes_list = list(Node_to_Node_pairs_dict.keys())\n",
    "random.seed(123)\n",
    "origin_nodes_list_subset = random.sample(origin_nodes_list, 99)\n",
    "del origin_nodes_list\n",
    "\n",
    "print(\"Creating Node_to_Node_pairs_dict_subset...\")\n",
    "Node_to_Node_pairs_dict_subset = {k: v for k, v in Node_to_Node_pairs_dict.items() if k in origin_nodes_list_subset}\n",
    "# Node_to_Node_pairs_dict_subset = Node_to_Node_pairs_dict\n",
    "\n",
    "del Node_to_Node_pairs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the total number of pairs in Node_to_Node_pairs_dict_subset from keys and values\n",
    "total_subset_pairs = 0\n",
    "\n",
    "for key, value in Node_to_Node_pairs_dict_subset.items():\n",
    "    total_subset_pairs += len(value)\n",
    "\n",
    "def chunks(data, SIZE=10):\n",
    "    #it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        it = iter(data)\n",
    "        if isinstance(data, dict):\n",
    "            yield {k: data[k] for k in list(it)[i:i + SIZE]}\n",
    "        else:\n",
    "            yield data[i:i + SIZE]\n",
    "\n",
    "# SIZE = 1000\n",
    "SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using single source dijkstra algorithm in igraph to find shortest paths for  80272 pairs...\n",
      "Creating chunks of Node_to_Node_pairs_dict_subset...\n",
      "Number of chunks to process:  10\n",
      "Processing chunk 1/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/88dwrhnx7m3cybxwl1p0rtq40000gn/T/ipykernel_78391/4124952000.py:19: RuntimeWarning: Couldn't reach some vertices. at src/paths/dijkstra.c:534\n",
      "  shortest_paths = g.get_shortest_paths(origin, to=destinations, weights='weight', output=\"vpath\", algorithm=\"dijkstra\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to find shortest paths for chunk  1 :  0.1250123659769694 minutes\n",
      "Total time for B_matrix update: 8.8126699924469 seconds\n",
      "Time getting path and lodes values: 0.13516473770141602 seconds\n",
      "Time updating matrix: 8.668071746826172 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.5163092486882557 %\n",
      "Processing chunk 2/10...\n",
      "Time taken to find shortest paths for chunk  2 :  0.08359413146972657 minutes\n",
      "Total time for B_matrix update: 15.634770154953003 seconds\n",
      "Time getting path and lodes values: 0.20527338981628418 seconds\n",
      "Time updating matrix: 15.41038179397583 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.5335055762237704 %\n",
      "Processing chunk 3/10...\n",
      "Time taken to find shortest paths for chunk  3 :  0.04723130067189534 minutes\n",
      "Total time for B_matrix update: 2.2917160987854004 seconds\n",
      "Time getting path and lodes values: 0.036699771881103516 seconds\n",
      "Time updating matrix: 2.2526769638061523 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.5515407490049198 %\n",
      "Processing chunk 4/10...\n",
      "Time taken to find shortest paths for chunk  4 :  0.1270291527112325 minutes\n",
      "Total time for B_matrix update: 5.985843896865845 seconds\n",
      "Time getting path and lodes values: 1.1101810932159424 seconds\n",
      "Time updating matrix: 4.868970632553101 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.5767061063739656 %\n",
      "Processing chunk 5/10...\n",
      "Time taken to find shortest paths for chunk  5 :  4.38242746591568 minutes\n",
      "Total time for B_matrix update: 204.6859369277954 seconds\n",
      "Time getting path and lodes values: 35.21793055534363 seconds\n",
      "Time updating matrix: 169.16060614585876 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.651363333235468 %\n",
      "Processing chunk 6/10...\n",
      "Time taken to find shortest paths for chunk  6 :  0.3824049115180969 minutes\n",
      "Total time for B_matrix update: 6.753366947174072 seconds\n",
      "Time getting path and lodes values: 1.2390015125274658 seconds\n",
      "Time updating matrix: 5.508155107498169 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.660171208314634 %\n",
      "Processing chunk 7/10...\n",
      "Time taken to find shortest paths for chunk  7 :  0.08331971565882365 minutes\n",
      "Total time for B_matrix update: 22.393782138824463 seconds\n",
      "Time getting path and lodes values: 4.8352906703948975 seconds\n",
      "Time updating matrix: 17.528494358062744 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.6698179286394349 %\n",
      "Processing chunk 8/10...\n",
      "Time taken to find shortest paths for chunk  8 :  0.05155121485392253 minutes\n",
      "Total time for B_matrix update: 6.856308937072754 seconds\n",
      "Time getting path and lodes values: 2.0429751873016357 seconds\n",
      "Time updating matrix: 4.798936128616333 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.6735927322447919 %\n",
      "Processing chunk 9/10...\n",
      "Time taken to find shortest paths for chunk  9 :  0.05790981849034627 minutes\n",
      "Total time for B_matrix update: 10.560778856277466 seconds\n",
      "Time getting path and lodes values: 1.9245171546936035 seconds\n",
      "Time updating matrix: 8.624072313308716 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.6761092679816963 %\n",
      "Processing chunk 10/10...\n",
      "Time taken to find shortest paths for chunk  10 :  0.11368136405944824 minutes\n",
      "Total time for B_matrix update: 44.412925004959106 seconds\n",
      "Time getting path and lodes values: 8.512495279312134 seconds\n",
      "Time updating matrix: 35.853843450546265 seconds\n",
      "Percent of B_matrix_weighted_array updated:  0.6828200299467753 %\n",
      "Time taken for all chunks:  10.955612734953563 minutes\n",
      "Estimated time for all pairs:  202.02163349391876 hours\n",
      "Number of missing paths:  173\n",
      "Percentage of missing paths: 0.21551724137931033%\n"
     ]
    }
   ],
   "source": [
    "print(\"Using single source dijkstra algorithm in igraph to find shortest paths for \", total_subset_pairs, \"pairs...\")\n",
    "\n",
    "print(\"Creating chunks of Node_to_Node_pairs_dict_subset...\")\n",
    "Node_to_Node_pairs_dict_subset_chunks = list(chunks(Node_to_Node_pairs_dict_subset, SIZE))\n",
    "\n",
    "print(\"Number of chunks to process: \", len(Node_to_Node_pairs_dict_subset_chunks))\n",
    "\n",
    "missing_paths = 0\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for i, chunk in enumerate(Node_to_Node_pairs_dict_subset_chunks):\n",
    "\n",
    "    chunk_time_start = time.time()\n",
    "\n",
    "    shortest_path_results = {}\n",
    "    print(f\"Processing chunk {i+1}/{len(Node_to_Node_pairs_dict_subset_chunks)}...\")\n",
    "    for origin, destinations in chunk.items():\n",
    "        shortest_paths = g.get_shortest_paths(origin, to=destinations, weights='weight', output=\"vpath\", algorithm=\"dijkstra\")\n",
    "        to_destination_dict = {}\n",
    "        for destination, path in zip(destinations, shortest_paths):\n",
    "            if len(path) == 0:\n",
    "                missing_paths += 1\n",
    "            else:\n",
    "                to_destination_dict[destination] = path\n",
    "\n",
    "        shortest_path_results[origin] = to_destination_dict\n",
    "\n",
    "    shortest_path_tuple_keys = {(origin, destination): path \n",
    "                            for origin, destinations in shortest_path_results.items() \n",
    "                            for destination, path in destinations.items()}\n",
    "\n",
    "    chunk_time_end = time.time()\n",
    "\n",
    "    print(\"Time taken to find shortest paths for chunk \", i+1, \": \", (chunk_time_end - chunk_time_start)/60, \"minutes\")\n",
    "\n",
    "    B_matrix_update_time_start = time.time()\n",
    "\n",
    "    # Initialize variables to track time spent in different parts of the loop\n",
    "    time_getting_path_and_lodes = 0\n",
    "    time_updating_matrix = 0\n",
    "\n",
    "    for key in shortest_path_tuple_keys:\n",
    "        start_time = time.time()\n",
    "        path = shortest_path_tuple_keys[key]\n",
    "        lodes_values = get_lodes_from_node_pair(key)\n",
    "        time_getting_path_and_lodes += time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        for j in range(len(path) - 1):\n",
    "            pair = (path[j], path[j+1])\n",
    "            reverse_pair = (path[j+1], path[j])\n",
    "\n",
    "            if pair in B_matrix_weighted_dict:\n",
    "                B_matrix_weighted_dict[pair][6:16] += lodes_values\n",
    "            elif reverse_pair in B_matrix_weighted_dict:\n",
    "                B_matrix_weighted_dict[reverse_pair][6:16] += lodes_values\n",
    "        \n",
    "        time_updating_matrix += time.time() - start_time\n",
    "\n",
    "    B_matrix_update_time_end = time.time()\n",
    "\n",
    "    # print(\"Time taken to update B_matrix_weighted_array for chunk \", i+1, \": \", (B_matrix_update_time_end - B_matrix_update_time_start)/60, \"minutes\")\n",
    "    # Print the total time and the time spent in each part\n",
    "    print(f\"Total time for B_matrix update: {B_matrix_update_time_end - B_matrix_update_time_start} seconds\")\n",
    "    print(f\"Time getting path and lodes values: {time_getting_path_and_lodes} seconds\")\n",
    "    print(f\"Time updating matrix: {time_updating_matrix} seconds\")\n",
    "\n",
    "    del shortest_path_tuple_keys\n",
    "\n",
    "    # find number of rows in B_matrix_weighted_array where the last 10 columns are not 0\n",
    "    non_zero_rows = np.where(B_matrix_weighted_array[:,-10:].any(axis=1))[0]\n",
    "    print(\"Percent of B_matrix_weighted_array updated: \", len(non_zero_rows)/B_matrix_weighted_array.shape[0] * 100, \"%\")\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print(\"Time taken for all chunks: \", (time_end - time_start)/60, \"minutes\")\n",
    "print(\"Estimated time for all pairs: \", (time_end - time_start)/60 * Node_to_Node_pairs_len/total_subset_pairs / 60, \"hours\")\n",
    "\n",
    "print(\"Number of missing paths: \", missing_paths)\n",
    "percentage_missing_paths = missing_paths/total_subset_pairs * 100\n",
    "print(\"Percentage of missing paths: \" + str(percentage_missing_paths) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting B_matrix_weighted_array to intermediate_files/B_matrix_weighted_array.pickle...\n"
     ]
    }
   ],
   "source": [
    "# Export B_matrix_weighted_array to a pickle file\n",
    "\n",
    "print(\"Exporting B_matrix_weighted_array to intermediate_files/B_matrix_weighted_array.pickle...\")\n",
    "with open(r'intermediate_files/B_matrix_weighted_array.pickle', 'wb') as handle:\n",
    "    pickle.dump(B_matrix_weighted_array, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
